{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e30353c-ca9d-4227-8580-f1b29910e6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features.csv with 1031 rows and 11 columns\n",
      "After merging estimation.csv: 1033 rows and 13 columns\n",
      "After merging stats.csv: 1033 rows and 21 columns\n",
      "After merging apartment_details.csv: 3513 rows and 32 columns\n",
      "After merging building_details.csv: 16945 rows and 43 columns\n",
      "After merging rental_terms.csv: 102681 rows and 50 columns\n",
      "After merging cian_apartments.csv: 102777 rows and 74 columns\n",
      "\n",
      "Columns with suffixes (indicating duplicates):\n",
      "- rental_period_cian\n",
      "\n",
      "Merged Dataset Information:\n",
      "Total number of rows: 102777\n",
      "Total number of columns: 74\n",
      "\n",
      "Columns in the merged dataset:\n",
      "['offer_id', 'has_refrigerator', 'has_dishwasher', 'has_washing_machine', 'has_air_conditioner', 'has_tv', 'has_internet', 'has_kitchen_furniture', 'has_room_furniture', 'has_bathtub', 'has_shower_cabin', 'estimated_price', 'estimated_price_clean', 'creation_date', 'creation_date_iso', 'updated_date', 'updated_date_iso', 'total_views', 'recent_views', 'unique_views', 'is_unpublished', 'layout', 'apartment_type', 'total_area', 'living_area', 'kitchen_area', 'ceiling_height', 'bathroom', 'balcony', 'sleeping_places', 'renovation', 'view', 'year_built', 'building_series', 'garbage_chute', 'elevators', 'building_type', 'ceiling_type', 'parking', 'entrances', 'heating', 'emergency', 'gas_supply', 'utilities_payment', 'security_deposit', 'commission', 'prepayment', 'rental_period', 'living_conditions', 'negotiable', 'offer_url', 'title', 'address', 'metro_station', 'neighborhood', 'district', 'description', 'status', 'updated_time', 'activity_date', 'unpublished_date', 'price_info', 'distance', 'price_value', 'rental_period_cian', 'utilities_type', 'commission_info', 'deposit_info', 'commission_value', 'deposit_value', 'cian_estimation_value', 'price_change_value', 'price_difference_value', 'cian_estimation']\n",
      "\n",
      "Preview of merged data (first 5 rows):\n",
      "    offer_id has_refrigerator has_dishwasher has_washing_machine  \\\n",
      "0  153165275              NaN            NaN                 NaN   \n",
      "1  153942662             True          False                True   \n",
      "2  153942662             True          False                True   \n",
      "3  153942662             True          False                True   \n",
      "4  153942662             True          False                True   \n",
      "\n",
      "  has_air_conditioner has_tv has_internet has_kitchen_furniture  \\\n",
      "0                 NaN    NaN          NaN                   NaN   \n",
      "1                True   True         True                  True   \n",
      "2                True   True         True                  True   \n",
      "3                True   True         True                  True   \n",
      "4                True   True         True                  True   \n",
      "\n",
      "  has_room_furniture has_bathtub  ... rental_period_cian  \\\n",
      "0                NaN         NaN  ...            От года   \n",
      "1               True       False  ...            От года   \n",
      "2               True       False  ...            От года   \n",
      "3               True       False  ...            От года   \n",
      "4               True       False  ...            От года   \n",
      "\n",
      "                               utilities_type  commission_info  \\\n",
      "0      комм. платежи включены (без счётчиков)     без комиссии   \n",
      "1  комм. платежи включены (счётчики включены)     комиссия 50%   \n",
      "2  комм. платежи включены (счётчики включены)     комиссия 50%   \n",
      "3  комм. платежи включены (счётчики включены)     комиссия 50%   \n",
      "4  комм. платежи включены (счётчики включены)     комиссия 50%   \n",
      "\n",
      "     deposit_info commission_value deposit_value cian_estimation_value  \\\n",
      "0  залог 99 000 ₽              NaN           NaN                   NaN   \n",
      "1  залог 75 000 ₽              NaN           NaN               73000.0   \n",
      "2  залог 75 000 ₽              NaN           NaN               73000.0   \n",
      "3  залог 75 000 ₽              NaN           NaN               73000.0   \n",
      "4  залог 75 000 ₽              NaN           NaN               73000.0   \n",
      "\n",
      "   price_change_value  price_difference_value  cian_estimation  \n",
      "0                 NaN                     NaN              NaN  \n",
      "1             -3000.0                 -2000.0              NaN  \n",
      "2             -3000.0                 -2000.0              NaN  \n",
      "3             -3000.0                 -2000.0              NaN  \n",
      "4             -3000.0                 -2000.0              NaN  \n",
      "\n",
      "[5 rows x 74 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_duplicates(df, file_name):\n",
    "    \"\"\"Check for duplicate offer_ids in a DataFrame and print results\"\"\"\n",
    "    duplicates = df[df.duplicated(subset=['offer_id'], keep=False)]\n",
    "    if len(duplicates) > 0:\n",
    "        dup_count = len(duplicates['offer_id'].unique())\n",
    "        total_dups = len(duplicates)\n",
    "        print(f\"⚠️ WARNING: {file_name} has {total_dups} duplicate rows ({dup_count} unique offer_ids)\")\n",
    "        print(f\"Example duplicates: {duplicates['offer_id'].unique()[:5].tolist()}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"✓ {file_name} has no duplicate offer_ids\")\n",
    "        return False\n",
    "\n",
    "def merge_csv_files(handle_duplicates=True):\n",
    "    \"\"\"\n",
    "    Merge specified CSV files using an outer join on offer_id with duplicate handling.\n",
    "    \n",
    "    Args:\n",
    "        handle_duplicates: If True, removes duplicate offer_ids from source files before merging\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Merged DataFrame containing data from all input CSV files\n",
    "    \"\"\"\n",
    "    # Define file list and handling functions\n",
    "    file_list = [\n",
    "        'features.csv',\n",
    "        'estimation.csv',\n",
    "        'stats.csv',\n",
    "        'apartment_details.csv',\n",
    "        'building_details.csv', \n",
    "        'rental_terms.csv',\n",
    "        'cian_apartments.csv'\n",
    "    ]\n",
    "    \n",
    "    # Check all files for duplicates first\n",
    "    print(\"Checking files for duplicate offer_ids:\")\n",
    "    for file_name in file_list:\n",
    "        df = pd.read_csv(file_name)\n",
    "        has_dups = check_duplicates(df, file_name)\n",
    "    \n",
    "    # Start with base file\n",
    "    df_features = pd.read_csv('features.csv')\n",
    "    if handle_duplicates and check_duplicates(df_features, 'features.csv'):\n",
    "        df_features = df_features.drop_duplicates(subset=['offer_id'], keep='first')\n",
    "    merged_df = df_features\n",
    "    print(f\"Loaded features.csv with {len(merged_df)} rows and {len(merged_df.columns)} columns\")\n",
    "    \n",
    "    # Merge estimation.csv\n",
    "    df_estimation = pd.read_csv('estimation.csv')\n",
    "    if handle_duplicates and check_duplicates(df_estimation, 'estimation.csv'):\n",
    "        df_estimation = df_estimation.drop_duplicates(subset=['offer_id'], keep='first')\n",
    "    merged_df = pd.merge(merged_df, df_estimation, on='offer_id', how='outer',\n",
    "                        suffixes=('', '_estimation'))\n",
    "    print(f\"After merging estimation.csv: {len(merged_df)} rows and {len(merged_df.columns)} columns\")\n",
    "    \n",
    "    # Merge stats.csv\n",
    "    df_stats = pd.read_csv('stats.csv')\n",
    "    if handle_duplicates and check_duplicates(df_stats, 'stats.csv'):\n",
    "        df_stats = df_stats.drop_duplicates(subset=['offer_id'], keep='first')\n",
    "    merged_df = pd.merge(merged_df, df_stats, on='offer_id', how='outer',\n",
    "                        suffixes=('', '_stats'))\n",
    "    print(f\"After merging stats.csv: {len(merged_df)} rows and {len(merged_df.columns)} columns\")\n",
    "    \n",
    "    # Merge apartment_details.csv\n",
    "    df_apartment = pd.read_csv('apartment_details.csv')\n",
    "    if handle_duplicates and check_duplicates(df_apartment, 'apartment_details.csv'):\n",
    "        df_apartment = df_apartment.drop_duplicates(subset=['offer_id'], keep='first')\n",
    "    merged_df = pd.merge(merged_df, df_apartment, on='offer_id', how='outer',\n",
    "                        suffixes=('', '_apartment'))\n",
    "    print(f\"After merging apartment_details.csv: {len(merged_df)} rows and {len(merged_df.columns)} columns\")\n",
    "    \n",
    "    # Merge building_details.csv\n",
    "    df_building = pd.read_csv('building_details.csv')\n",
    "    if handle_duplicates and check_duplicates(df_building, 'building_details.csv'):\n",
    "        df_building = df_building.drop_duplicates(subset=['offer_id'], keep='first')\n",
    "    merged_df = pd.merge(merged_df, df_building, on='offer_id', how='outer',\n",
    "                        suffixes=('', '_building'))\n",
    "    print(f\"After merging building_details.csv: {len(merged_df)} rows and {len(merged_df.columns)} columns\")\n",
    "    \n",
    "    # Merge rental_terms.csv - with specific suffix to handle duplicate columns\n",
    "    df_terms = pd.read_csv('rental_terms.csv')\n",
    "    if handle_duplicates and check_duplicates(df_terms, 'rental_terms.csv'):\n",
    "        df_terms = df_terms.drop_duplicates(subset=['offer_id'], keep='first')\n",
    "    merged_df = pd.merge(merged_df, df_terms, on='offer_id', how='outer',\n",
    "                        suffixes=('', '_terms'))\n",
    "    print(f\"After merging rental_terms.csv: {len(merged_df)} rows and {len(merged_df.columns)} columns\")\n",
    "    \n",
    "    # Merge cian_apartments.csv last as it has several duplicate columns\n",
    "    df_cian = pd.read_csv('cian_apartments.csv')\n",
    "    if handle_duplicates and check_duplicates(df_cian, 'cian_apartments.csv'):\n",
    "        df_cian = df_cian.drop_duplicates(subset=['offer_id'], keep='first')\n",
    "    merged_df = pd.merge(merged_df, df_cian, on='offer_id', how='outer',\n",
    "                        suffixes=('', '_cian'))\n",
    "    print(f\"After merging cian_apartments.csv: {len(merged_df)} rows and {len(merged_df.columns)} columns\")\n",
    "    \n",
    "    # Clean up column names - remove any empty suffixes that might have been added\n",
    "    merged_df.columns = [col.replace('_', '') if col.endswith('_') else col \n",
    "                         for col in merged_df.columns]\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "def main():\n",
    "    # Let user know what's happening\n",
    "    print(\"\\nRunning merge process with duplicate handling...\\n\")\n",
    "    \n",
    "    # Merge the CSV files with duplicate handling\n",
    "    merged_dataframe = merge_csv_files(handle_duplicates=True)\n",
    "    \n",
    "    # Check for any remaining duplicates in the final dataset\n",
    "    print(\"\\nChecking for duplicates in final merged dataset:\")\n",
    "    duplicates = merged_dataframe[merged_dataframe.duplicated(subset=['offer_id'], keep=False)]\n",
    "    if len(duplicates) > 0:\n",
    "        dup_count = len(duplicates['offer_id'].unique())\n",
    "        total_dups = len(duplicates)\n",
    "        print(f\"⚠️ WARNING: Final dataset still has {total_dups} duplicate rows ({dup_count} unique offer_ids)\")\n",
    "        \n",
    "        # Print a sample of the duplicate records\n",
    "        print(\"\\nSample of duplicate offer_ids in final dataset:\")\n",
    "        example_id = duplicates['offer_id'].iloc[0]\n",
    "        print(f\"Records for offer_id {example_id}:\")\n",
    "        print(merged_dataframe[merged_dataframe['offer_id'] == example_id].head(2))\n",
    "    else:\n",
    "        print(\"✓ Final dataset has no duplicate offer_ids\")\n",
    "    \n",
    "    # Print a list of columns with suffixes to help identify duplicates\n",
    "    suffix_columns = [col for col in merged_dataframe.columns if '_terms' in col or '_cian' in col \n",
    "                      or '_estimation' in col or '_stats' in col or '_apartment' in col \n",
    "                      or '_building' in col]\n",
    "    if suffix_columns:\n",
    "        print(\"\\nColumns with suffixes (indicating duplicates):\")\n",
    "        for col in suffix_columns:\n",
    "            print(f\"- {col}\")\n",
    "    \n",
    "    # Save the merged DataFrame\n",
    "    merged_dataframe.to_csv('merged_apartments_data.csv', index=False, encoding='utf-8')\n",
    "    print(\"\\nMerged data saved to 'merged_apartments_data.csv'\")\n",
    "    \n",
    "    # Display information about the merged dataset\n",
    "    print(\"\\nMerged Dataset Information:\")\n",
    "    print(f\"Total number of rows: {len(merged_dataframe)}\")\n",
    "    print(f\"Total number of columns: {len(merged_dataframe.columns)}\")\n",
    "    \n",
    "    # Print all column names\n",
    "    print(\"\\nColumns in the merged dataset:\")\n",
    "    print(merged_dataframe.columns.tolist())\n",
    "    \n",
    "    # Optional: Preview the data\n",
    "    print(\"\\nPreview of merged data (first 5 rows):\")\n",
    "    print(merged_dataframe.head(5))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dc8415-54da-4f4b-b6af-a2a13ff20d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
